{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text-sentiment-analysis-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNR0a/mwfYO++OaC38xEqui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nivratti/Text_Classification/blob/master/Text_sentiment_analysis_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0RyGlWpct5y",
        "colab_type": "text"
      },
      "source": [
        "# Text sentiment analysis on Amazon Reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzu4UWqO3iH8",
        "colab_type": "text"
      },
      "source": [
        "# Connect Google Colab with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G64KSaO3ju9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJcNFwSE3ns1",
        "colab_type": "code",
        "outputId": "96f96203-c76c-428a-dff0-653e9c029366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47BMevlphFtj",
        "colab_type": "text"
      },
      "source": [
        "# Execution Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6s_b71thFF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66f355c0-3530-47c6-8455-9e20f4eec45f"
      },
      "source": [
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.6/dist-packages (0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR8lB67Y4NsF",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow with GPU -- For faster training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kJQBOgL4aVT",
        "colab_type": "text"
      },
      "source": [
        "Enabling and testing the GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WWt4C1h4d7L",
        "colab_type": "text"
      },
      "source": [
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "Navigate to Editâ†’Notebook Settings\n",
        "select GPU from the Hardware Accelerator drop-down\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqrHWhM74Q8X",
        "colab_type": "code",
        "outputId": "84bd95ed-daa6-44a9-eb3d-538d1db44f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Found GPU at: /device:GPU:0\n",
            "time: 7.24 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyI5VRJj4vX-",
        "colab_type": "text"
      },
      "source": [
        "# Global vars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWXwvsSpax-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3b3057b-f2df-498d-8eff-b7dbdbe6f5b4"
      },
      "source": [
        "import os\n",
        "\n",
        "# project folder on rive containing dataset, trained model and other files\n",
        "DRIVE_PROJECT_BASE_DIR = \"/content/gdrive/My Drive/deep_learning/text_sentiment_analysis/\"\n",
        "\n",
        "BASE_DATASET_DIR = os.path.join(\n",
        "    DRIVE_PROJECT_BASE_DIR , \"dataset\"\n",
        ")\n",
        "\n",
        "input_zipfile = os.path.join(\n",
        "    BASE_DATASET_DIR , \"amazonreviews.zip\"\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.55 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDhu4lg2hvvU",
        "colab_type": "text"
      },
      "source": [
        "# Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mre7XMqbhxX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2fe3d882-2ccb-4042-e1f0-b8576ec466a9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.keras import models, layers, optimizers\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import bz2\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "import re\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjGz0OM-hYfw",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWXPtpPfhbeN",
        "colab_type": "text"
      },
      "source": [
        "## Unzip zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX5oim71gktM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "cc3575b9-d569-4020-b40c-1ee290544f31"
      },
      "source": [
        "!unzip \"$input_zipfile\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/deep_learning/text_sentiment_analysis/dataset/amazonreviews.zip\n",
            "replace test.ft.txt.bz2? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MrKJNOwh8un",
        "colab_type": "text"
      },
      "source": [
        "## Reading the text\n",
        "\n",
        "The text is held in a compressed format. Luckily, we can still read it line by line. The first word gives the label, so we have to convert that into a number and then take the rest to be the comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttKb1NyHiAnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels_and_texts(file):\n",
        "    labels = []\n",
        "    texts = []\n",
        "    for line in bz2.BZ2File(file):\n",
        "        x = line.decode(\"utf-8\")\n",
        "        labels.append(int(x[9]) - 1)\n",
        "        texts.append(x[10:].strip())\n",
        "    return np.array(labels), texts\n",
        "\n",
        "train_labels, train_texts = get_labels_and_texts('train.ft.txt.bz2')\n",
        "test_labels, test_texts   = get_labels_and_texts('test.ft.txt.bz2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSdzQsVXjv2x",
        "colab_type": "text"
      },
      "source": [
        "## View data shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv0EjDAkjyqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print shapes\n",
        "print(\"Shape of train_labels: {}\".format(train_labels.shape))\n",
        "print(\"length of train_texts: {}\".format(len(train_texts)))\n",
        "\n",
        "print(\"Shape of test_labels: {}\".format(test_labels.shape))\n",
        "print(\"length of test_texts: {}\".format(len(test_texts)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrQ5V1KulP8L",
        "colab_type": "text"
      },
      "source": [
        "# Text Preprocessing\n",
        "\n",
        "The first thing I'm going to do to process the text is to lowercase everything and then remove non-word characters. I replace these with spaces since most are going to be punctuation. Then I'm going to just remove any other characters (like letters with accents). It could be better to replace some of these with regular ascii characters but I'm just going to ignore that here. It also turns out if you look at the counts of the different characters that there are very few unusual characters in this corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as7awfrxlbWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "NON_ALPHANUM = re.compile(r'[\\W]')\n",
        "NON_ASCII = re.compile(r'[^a-z0-1\\s]')\n",
        "def normalize_texts(texts):\n",
        "    normalized_texts = []\n",
        "    for text in texts:\n",
        "        lower = text.lower()\n",
        "        no_punctuation = NON_ALPHANUM.sub(r' ', lower)\n",
        "        no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\n",
        "        normalized_texts.append(no_non_ascii)\n",
        "    return normalized_texts\n",
        "        \n",
        "train_texts = normalize_texts(train_texts)\n",
        "test_texts = normalize_texts(test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFoYRZWGlxvI",
        "colab_type": "text"
      },
      "source": [
        "# Train/Validation Split\n",
        "Now I'm going to set aside 20% of the training set for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX__S_cyl0A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels, random_state=57643892, test_size=0.2\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIJMD-Bcl4aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Shape of train_labels: {}\".format(train_labels.shape))\n",
        "print(\"length of train_texts: {}\".format(len(train_texts)))\n",
        "\n",
        "print(\"Shape of val_labels: {}\".format(val_labels.shape))\n",
        "print(\"length of val_texts: {}\".format(len(val_texts)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJC2adXRm9RM",
        "colab_type": "text"
      },
      "source": [
        "viewing top 5 labels and first training text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYLzjM6Ll6Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_labels[:5])\n",
        "print(train_texts[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsGfPooUmnYU",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization\n",
        "\n",
        "Now I will just run a Tokenizer using the top 12000 words as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ee1ST07mly7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_FEATURES = 12000\n",
        "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
        "val_texts = tokenizer.texts_to_sequences(val_texts)\n",
        "test_texts = tokenizer.texts_to_sequences(test_texts)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Tp5yLKhnQfq",
        "colab_type": "text"
      },
      "source": [
        "# Padding Sequences\n",
        "In order to use batches effectively, I'm going to need to take my sequences and turn them into sequences of the same length. I'm just going to make everything here the length of the longest sentence in the training set. I'm not dealing with this here, but it may be advantageous to have variable lengths so that each batch contains sentences of similar lengths. This might help mitigate issues that arise from having too many padded elements in a sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUcUFp70niAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
        "\n",
        "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH)\n",
        "val_texts = pad_sequences(val_texts, maxlen=MAX_LENGTH)\n",
        "test_texts = pad_sequences(test_texts, maxlen=MAX_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhQqTEvroLWw",
        "colab_type": "text"
      },
      "source": [
        "# Save Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skERo2ePoNsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "tokenizer_info = {\n",
        "    \"tokenizer\"   : tokenizer,\n",
        "    \"MAX_LENGTH\"  : MAX_LENGTH,\n",
        "    \"MAX_FEATURES\": MAX_FEATURES,\n",
        "}\n",
        "with open('tokenizer_info.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer_info, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn9HpP_VnrQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make some space\n",
        "del tokenizer\n",
        "\n",
        "import gc\n",
        "\n",
        "print(f\"total objects in memory --{gc.get_count()}\")\n",
        "\n",
        "# collecting memory\n",
        "gc.collect()\n",
        "print(f\"After garbage collecor- objects in memory --{gc.get_count()}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEJFgOTPpsy7",
        "colab_type": "text"
      },
      "source": [
        "# labels info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYIW_fG4psWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_dict = {\n",
        "    \"negative\": 0,\n",
        "    \"positive\": 1,\n",
        "}\n",
        "num_classes = len(labels_dict.items())\n",
        "print(f\"num_classes : {num_classes}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1p1VQOOpb8c",
        "colab_type": "text"
      },
      "source": [
        "# convert to categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS9lj8m0peg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_y = to_categorical(train_labels, num_classes=num_classes, dtype='float32')\n",
        "test_y = to_categorical(test_labels, num_classes=num_classes, dtype='float32')\n",
        "val_y = to_categorical(val_labels, num_classes=num_classes, dtype='float32')\n",
        "\n",
        "# Print shapes\n",
        "print(\"Shape of train_y: {}\".format(train_y.shape))\n",
        "print(\"Shape of test_y: {}\".format(test_y.shape))\n",
        "print(\"Shape of val_y: {}\".format(val_y.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXDLRs_kv0rr",
        "colab_type": "text"
      },
      "source": [
        "view single record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_i1e2Nlv25Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8_XLgBupHt7",
        "colab_type": "text"
      },
      "source": [
        "# Deep learning Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QEP_V79rKi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,GRU,LSTM,Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import SpatialDropout1D,Dropout,Bidirectional,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Flatten\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyCG3Jo70KhX",
        "colab_type": "text"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSFoQqC40WLp",
        "colab_type": "text"
      },
      "source": [
        "### Plotting accuracy and loss graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzZsvtTN0NQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_accuracy_loss(history):\n",
        "  axes = plt.axes()\n",
        "  # axes.set_ylim([0, 1])\n",
        "\n",
        "  # Plot training & validation accuracy values\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training & validation loss values\n",
        "  axes = plt.axes()\n",
        "  # axes.set_ylim([0, 1])\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UIVIQlNqfFk",
        "colab_type": "text"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai8Atg1JpHFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_dim = 64\n",
        "\n",
        "model_LSTM = Sequential()\n",
        "model_LSTM.add(Embedding(MAX_FEATURES, embed_dim, input_length=MAX_LENGTH, mask_zero=True))\n",
        "model_LSTM.add(LSTM(64,dropout=0.4,return_sequences=True))\n",
        "model_LSTM.add(LSTM(32,dropout=0.5,return_sequences=False))\n",
        "model_LSTM.add(Dense(num_classes, activation='softmax'))\n",
        "model_LSTM.compile(loss = 'categorical_crossentropy', optimizer=Adam(lr = 0.001), metrics = ['accuracy'])\n",
        "model_LSTM.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMEwv3CVrr9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model\n",
        "epochs = 2\n",
        "batch_size = 2048 # 64 # use more if gpu available - for faster processing \n",
        "history = model_LSTM.fit(\n",
        "    train_texts, train_y, \n",
        "    validation_data=(val_texts, val_y), \n",
        "    epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2SXKvR-0pn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accuracy_loss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DotRCDcz-Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preds = model_LSTM.predict(test_texts)\n",
        "\n",
        "# print('Accuracy score: {:0.4}'.format(accuracy_score(test_labels, 1 * (preds > 0.5))))\n",
        "# print('F1 score: {:0.4}'.format(f1_score(test_labels, 1 * (preds > 0.5))))\n",
        "# print('ROC AUC score: {:0.4}'.format(roc_auc_score(test_labels, preds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrtftuHM2xo2",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Lllyzk2zGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cnn = Sequential()\n",
        "\n",
        "model_cnn.add(Embedding(MAX_FEATURES, embed_dim, input_length=MAX_LENGTH))\n",
        "model_cnn.add(Dropout(0.2))\n",
        "\n",
        "model_cnn.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model_cnn.add(GlobalMaxPooling1D())\n",
        "\n",
        "model_cnn.add(Dense(hidden_dims))\n",
        "model_cnn.add(Dropout(0.2))\n",
        "model_cnn.add(Activation('relu'))\n",
        "\n",
        "model_cnn.add(Dense(num_classes))\n",
        "model_cnn.add(Activation('softmax'))\n",
        "\n",
        "model_cnn.compile(loss = 'categorical_crossentropy', optimizer=Adam(lr = 0.001), metrics = ['accuracy'])\n",
        "\n",
        "print(model_cnn.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6b1H4tC7_Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model\n",
        "epochs = 2\n",
        "batch_size = 2048 # 64 # use more if gpu available - for faster processing \n",
        "history = model_cnn.fit(\n",
        "    train_texts, train_y, \n",
        "    validation_data=(val_texts, val_y), \n",
        "    epochs=epochs, \n",
        "    batch_size=batch_size, verbose=1, shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4GbFISA8m4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accuracy_loss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pvZMGLL-AAg",
        "colab_type": "text"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF9Yjw-V-Cfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gru_model():\n",
        "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
        "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
        "    x = layers.CuDNNGRU(128, return_sequences=True)(embedded)\n",
        "    x = layers.CuDNNGRU(128)(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.Dense(100, activation='relu')(x)\n",
        "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = models.Model(inputs=sequences, outputs=predictions)\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "    \n",
        "gru_model = build_gru_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0uCYxaK-Ibi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2\n",
        "batch_size = 2048 # 128 # use more if gpu available - for faster processing \n",
        "\n",
        "gru_model.fit(\n",
        "    train_texts, \n",
        "    train_y, \n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(val_texts, val_y),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CkStWUgCrOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accuracy_loss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v40BIR1CU9s-",
        "colab_type": "text"
      },
      "source": [
        "## Bidirectional-GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLRyUjNKaXDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_bidirectional_gru():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(MAX_FEATURES, embed_dim, input_length=MAX_LENGTH))\n",
        "\tmodel.add(SpatialDropout1D(0.25))\n",
        "\tmodel.add(Bidirectional(GRU(64,dropout=0.4,return_sequences = True)))\n",
        "\tmodel.add(Bidirectional(GRU(32,dropout=0.5,return_sequences = False)))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\tmodel.compile(\n",
        "\t\tloss = 'categorical_crossentropy', optimizer=Adam(lr = 0.001), \n",
        "\t\tmetrics = ['accuracy']\n",
        "\t)\n",
        "\treturn model\n",
        "\t\n",
        "bidirectional_gru_model = build_bidirectional_gru()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXwIB0XTakpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2\n",
        "batch_size = 2048 # 128 # use more if gpu available - for faster processing \n",
        "\n",
        "bidirectional_gru_model.fit(\n",
        "    train_texts, \n",
        "    train_y, \n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(val_texts, val_y),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULfHZEkMazVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accuracy_loss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Js9baOEa-Bk",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_p38f81cWWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "model = LinearSVC()\n",
        "model.fit(train_texts, train_labels)\n",
        "y_pred = model.predict(val_texts)\n",
        "\n",
        "print(f\"Accuracy : {accuracy_score(val_labels, y_pred)}\")\n",
        "\n",
        "conf_mat = confusion_matrix(val_labels, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='3.0f', cmap=\"summer\", xticklabels=classes, yticklabels=classes)\n",
        "plt.title('Confusion_matrix', y=1.05, size=15)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewJetRjRd0Us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}